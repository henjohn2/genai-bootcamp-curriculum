{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metadata RAG Workflow**\n",
    "\n",
    "By working through this Jupyter Notebook together, we'll gain hands-on experience in using LangChain to generate column descriptions for rows with missing values in a dataset. We'll learn how to leverage the LlamaCpp language model and few-shot learning techniques to generate descriptions based on semantically similar examples.\n",
    "\n",
    "Let's dive in and start generating those column descriptions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the following packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-community==0.0.31 sentence-transformers==2.6.1 pandas faiss-cpu==1.8.0 openpyxl transformers==4.37.2 datasets peft==0.8.2\n",
    "!pip install accelerate bitsandbytes trl safetensors lm-eval gradio flask pgvector sentence-transformers langchain psycopg2-binary tiktoken openai pypdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We'll start by importing the necessary libraries from LangChain, LangChain Community, and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "#from langchain_community.llms import CTransformers, LlamaCpp <-- For open source runnning on CPU LlamaCppp = GGUF models, CTransformers .bin\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a cosine similarity function to compare the similarity between two strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(reference: str, prediction: str) -> str:\n",
    "    model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    embedding_1 = model.encode(reference, convert_to_tensor=True)\n",
    "    embedding_2 = model.encode(prediction, convert_to_tensor=True)\n",
    "    similarity_score = util.pytorch_cos_sim(embedding_1, embedding_2).item()\n",
    "    return f\"{similarity_score:.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll initialize the LlamaCpp language model with the specified parameters, such as the model path, temperature, maximum tokens, and batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FIRST TIME YOU RUN THIS, IT MIGHT TAKE A WHILE\n",
    "\n",
    "model_path_or_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path_or_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path_or_id,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    #use_flash_attention_2=True,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    load_in_4bit=True\n",
    ")\n",
    "\n",
    "def llm(prompt):\n",
    "    \"\"\"Convenience function for generating model output\"\"\"\n",
    "    # Tokenize the input\n",
    "    input_ids = tokenizer(\n",
    "        prompt, \n",
    "        return_tensors=\"pt\", \n",
    "        truncation=True).input_ids.cuda()\n",
    "    \n",
    "    # Generate new tokens based on the prompt, up to max_new_tokens\n",
    "    # Sample aacording to the parameter\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids, \n",
    "            max_new_tokens=20, \n",
    "            do_sample=True, \n",
    "            top_p=0.9,\n",
    "            temperature=0.1,\n",
    "            use_cache=True\n",
    "        )\n",
    "    return tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]\n",
    "\n",
    "# Initialize the LlamaCpp language model\n",
    "#llm = LlamaCpp(\n",
    "#    model_path=\"models/phi-2.Q5_K_M.gguf\",\n",
    "#    temperature=0.01,\n",
    "#    max_tokens=30,\n",
    "#    n_gpu_layers=-1,\n",
    "#    n_batch=512,\n",
    "#    f16_kv=True,\n",
    "#    verbose=False,\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define an example prompt template using the PromptTemplate class, which specifies the input variables and the template string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the example prompt template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load the metadata from an Excel file using pandas and display the first 5 rows of the DataFrame to get a glimpse of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>COLUMN_FULL_NAME</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <th>COLUMN_DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PARK</td>\n",
       "      <td>FN</td>\n",
       "      <td>Full Name</td>\n",
       "      <td>STRING</td>\n",
       "      <td>This column contains the full name of the pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PARK</td>\n",
       "      <td>AG</td>\n",
       "      <td>Age</td>\n",
       "      <td>INTEGER</td>\n",
       "      <td>This column contains the age of the person att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PARK</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Location</td>\n",
       "      <td>STRING</td>\n",
       "      <td>This column contains the location of the park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PARK</td>\n",
       "      <td>DT</td>\n",
       "      <td>DATE</td>\n",
       "      <td>DATE</td>\n",
       "      <td>This column contains the date of the visit to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PARK</td>\n",
       "      <td>TM</td>\n",
       "      <td>TIME</td>\n",
       "      <td>TIME</td>\n",
       "      <td>This column contains the time of visit to the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TABLE_NAME COLUMN_NAME COLUMN_FULL_NAME DATA_TYPE  \\\n",
       "0       PARK          FN        Full Name    STRING   \n",
       "1       PARK          AG              Age   INTEGER   \n",
       "2       PARK         LOC         Location    STRING   \n",
       "3       PARK          DT             DATE      DATE   \n",
       "4       PARK          TM             TIME      TIME   \n",
       "\n",
       "                                  COLUMN_DESCRIPTION  \n",
       "0  This column contains the full name of the pers...  \n",
       "1  This column contains the age of the person att...  \n",
       "2      This column contains the location of the park  \n",
       "3  This column contains the date of the visit to ...  \n",
       "4  This column contains the time of visit to the ...  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the metadata from an Excel file\n",
    "metadata = \"data/demo_excel.xlsx\"\n",
    "df = pd.read_excel(metadata)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll drop rows with missing values from the DataFrame to create a complete dataset that we can use as examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop rows with missing values\n",
    "df_complete = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a list of examples from the complete rows by applying a lambda function to each row. The examples will consist of the column name, full name, table name, and data type as input, and the column description as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of examples from the complete rows\n",
    "examples = df_complete.apply(\n",
    "    lambda row: {\n",
    "        \"input\": f\"{row['TABLE_NAME']},{row['COLUMN_NAME']},{row['COLUMN_FULL_NAME']},{row['DATA_TYPE']}\",\n",
    "        \"output\": row[\"COLUMN_DESCRIPTION\"],\n",
    "    },\n",
    "    axis=1,\n",
    ").tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll initialize the SemanticSimilarityExampleSelector using the examples, embeddings, and vectorstore class. This selector will help us find the most similar examples based on semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the SemanticSimilarityExampleSelector\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples=examples,\n",
    "    embeddings=HuggingFaceEmbeddings(\n",
    "        model_name=\"all-MiniLM-L6-v2\",\n",
    "        model_kwargs={\"device\": \"cpu\"},\n",
    "    ),\n",
    "    vectorstore_cls=FAISS,\n",
    "    k=5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a few-shot prompt template using the FewShotPromptTemplate class. This template will include the example selector, example prompt, prefix, suffix, and input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the few-shot prompt template\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"You are a column description generator. Given the following Examples below \",\n",
    "    suffix=\"predict the Output for the given input \\nInput: {metadata}\\nOutput:\",\n",
    "    input_variables=[\"metadata\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll select the rows with missing values from the original DataFrame to focus on the rows that need column descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select rows with missing values\n",
    "df_empty = df[df.isnull().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll iterate over the first 5 rows with missing values to generate column descriptions for them. For each row, we'll create a pre-prompt string using the column name, full name, and data type. We'll format the few-shot prompt template with the pre-prompt string to create a complete prompt. We'll print the generated prompt to see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PROMPT:\n",
      "You are a column description generator. Given the following Examples below \n",
      "\n",
      "Input: ART_GALLERY,AN,Art Gallery Name,STRING\n",
      "Output: This column contains the name of the art gallery\n",
      "\n",
      "Input: DANCE_STUDIO,DS,Dance Studio Name,STRING\n",
      "Output: This column contains the name of the dance studio\n",
      "\n",
      "Input: GYM,GN,Gym Name,STRING\n",
      "Output: This column contains the name of the gym\n",
      "\n",
      "Input: SCHOOL,SN,School Name,STRING\n",
      "Output: This column contains the name of the school\n",
      "\n",
      "Input: ZOO,ZN,Zoo Name,STRING\n",
      "Output: This column contains the name of the zoo\n",
      "\n",
      "predict the Output for the given input \n",
      "Input: LAKESIDE,LS,Lakeside Name,STRING\n",
      "Output: \n",
      "\n",
      "Model Response:   This column contains the name of the lakeside\n",
      "\n",
      "Similarity Score (0 - Bad, 1 - Perfect Match): 1.00 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, row in df_empty.head(1).iterrows(): #We iterate over .head(x) rows\n",
    "\n",
    "    #Here we collect the examples we want to parse for the output on top of the k-examples\n",
    "    pre_prompt = f\"{row['TABLE_NAME']},{row['COLUMN_NAME']},{row['COLUMN_FULL_NAME']},{row['DATA_TYPE']}\"\n",
    "\n",
    "    #Now we load the target metadata into similar_prompt\n",
    "    prompt = similar_prompt.format(metadata=pre_prompt)\n",
    "    \n",
    "    #Here what the final prompt looks like \n",
    "    print(f\"\\n\\nPROMPT:\\n{prompt} \\n\")\n",
    "\n",
    "    #Here we parse the prompt to the LLM and receive the models repsonse\n",
    "    response = llm.invoke(prompt)\n",
    "    print(\"Model Response: \" , response)\n",
    "\n",
    "    #Here we compare the response we want, with the model response using cosine similarity\n",
    "    sim = similarity(\"This column contains the name of the Lakeside\", response)\n",
    "    print(f\"Similarity Score (0 - Bad, 1 - Perfect Match): {sim} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll invoke the LlamaCpp language model with the generated prompt to generate the column description.\n",
    "\n",
    "Finally, we'll print the generated column description to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'similar_prompt = FewShotPromptTemplate(\\n    # We provide an ExampleSelector instead of examples.\\n    example_selector=example_selector,\\n    example_prompt=example_prompt,\\n    prefix=\"You are a column description generator. Given the following examples of Table Name, Column Name, Column Full Name and Data Type to Column Description below\",\\n    suffix=\"Predict the Column Description for the given Table Name, Column Name, Column Full Name and Data Type \\nInput: {metadata}\\nOutput:\",\\n    input_variables=[\"metadata\"],\\n)'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''similar_prompt = FewShotPromptTemplate(\n",
    "    # We provide an ExampleSelector instead of examples.\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"You are a column description generator. Given the following examples of Table Name, Column Name, Column Full Name and Data Type to Column Description below\",\n",
    "    suffix=\"Predict the Column Description for the given Table Name, Column Name, Column Full Name and Data Type \\nInput: {metadata}\\nOutput:\",\n",
    "    input_variables=[\"metadata\"],\n",
    ")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Noticed its going abit wrong?** \n",
    "Play around with the prompt template (example that worked for me above), model paramaters and K-samples "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
